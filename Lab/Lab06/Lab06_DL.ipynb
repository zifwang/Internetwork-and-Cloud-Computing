{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data by using pandas lib\n",
    "df = pd.read_csv('data_banknote_authentication.txt', sep=\",\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(df):\n",
    "    \"\"\"\n",
    "        Function to generate training data and testing data\n",
    "        Argument: df dataframe (type pd)\n",
    "        Returns: \n",
    "                x_train_shuffled\n",
    "                y_train_shuffled\n",
    "                x_test_shuffled\n",
    "                y_test_shuffled\n",
    "    \"\"\"\n",
    "    pos_data_type_1 = 0\n",
    "    for i in range (0,len(df[4])):\n",
    "        if df[4][i] == 1:\n",
    "            pos_data_type_1 = i\n",
    "            break\n",
    "    \n",
    "    # Generate Data\n",
    "    \n",
    "    length = len(df)\n",
    "    num_elements = len(df.keys())\n",
    "    \n",
    "    x_train = np.zeros((length-400,num_elements-1))\n",
    "    y_train = np.zeros((length-400,1))\n",
    "    x_test = np.zeros((400,num_elements-1))\n",
    "    y_test = np.zeros((400,1))\n",
    "    \n",
    "    for i in range (0,num_elements-1):\n",
    "        x_test[0:200,i] = df[i][0:200]\n",
    "        x_test[200:,i] = df[i][pos_data_type_1:pos_data_type_1+200]\n",
    "        x_train[0:pos_data_type_1-200,i] = df[i][200:pos_data_type_1]\n",
    "        x_train[pos_data_type_1-200:,i] = df[i][pos_data_type_1+200:]\n",
    "    \n",
    "    y_test[0:200,0] = df[4][0:200]\n",
    "    y_test[200:,0] = df[4][pos_data_type_1:pos_data_type_1+200]\n",
    "    y_train[0:pos_data_type_1-200,0] = df[4][200:pos_data_type_1]\n",
    "    y_train[pos_data_type_1-200:,0] = df[4][pos_data_type_1+200:]\n",
    "    \n",
    "    #  Shuffle\n",
    "    pi_trained = np.random.permutation(x_train.shape[0])\n",
    "    x_train_shuffled = x_train[pi_trained]\n",
    "    y_train_shuffled = y_train[pi_trained]\n",
    "    y_train_shuffled = y_train_shuffled.reshape(y_train_shuffled.shape[0],)\n",
    "    \n",
    "    pi_test = np.random.permutation(x_test.shape[0])\n",
    "    x_test_shuffled = x_test[pi_test]\n",
    "    y_test_shuffled = y_test[pi_test]\n",
    "    y_test_shuffled = y_test_shuffled.reshape(y_test_shuffled.shape[0],)\n",
    "    \n",
    "    return x_train_shuffled, y_train_shuffled, x_test_shuffled, y_test_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "972/972 [==============================] - 1s 885us/step - loss: 0.8436 - acc: 0.5689\n",
      "Epoch 2/25\n",
      "972/972 [==============================] - 0s 115us/step - loss: 0.5808 - acc: 0.7233\n",
      "Epoch 3/25\n",
      "972/972 [==============================] - 0s 131us/step - loss: 0.4034 - acc: 0.8117\n",
      "Epoch 4/25\n",
      "972/972 [==============================] - 0s 152us/step - loss: 0.3333 - acc: 0.8591\n",
      "Epoch 5/25\n",
      "972/972 [==============================] - 0s 133us/step - loss: 0.2603 - acc: 0.9012\n",
      "Epoch 6/25\n",
      "972/972 [==============================] - 0s 131us/step - loss: 0.1948 - acc: 0.9300\n",
      "Epoch 7/25\n",
      "972/972 [==============================] - 0s 138us/step - loss: 0.1714 - acc: 0.9527\n",
      "Epoch 8/25\n",
      "972/972 [==============================] - 0s 135us/step - loss: 0.1576 - acc: 0.9537\n",
      "Epoch 9/25\n",
      "972/972 [==============================] - 0s 121us/step - loss: 0.1276 - acc: 0.9609\n",
      "Epoch 10/25\n",
      "972/972 [==============================] - 0s 113us/step - loss: 0.1112 - acc: 0.9691\n",
      "Epoch 11/25\n",
      "972/972 [==============================] - 0s 129us/step - loss: 0.1033 - acc: 0.9712\n",
      "Epoch 12/25\n",
      "972/972 [==============================] - 0s 141us/step - loss: 0.0899 - acc: 0.9753\n",
      "Epoch 13/25\n",
      "972/972 [==============================] - 0s 134us/step - loss: 0.0762 - acc: 0.9877\n",
      "Epoch 14/25\n",
      "972/972 [==============================] - 0s 229us/step - loss: 0.0773 - acc: 0.9763\n",
      "Epoch 15/25\n",
      "972/972 [==============================] - 0s 128us/step - loss: 0.0625 - acc: 0.9846\n",
      "Epoch 16/25\n",
      "972/972 [==============================] - 0s 116us/step - loss: 0.0711 - acc: 0.9794\n",
      "Epoch 17/25\n",
      "972/972 [==============================] - 0s 122us/step - loss: 0.0548 - acc: 0.9856\n",
      "Epoch 18/25\n",
      "972/972 [==============================] - 0s 153us/step - loss: 0.0560 - acc: 0.9866\n",
      "Epoch 19/25\n",
      "972/972 [==============================] - 0s 196us/step - loss: 0.0535 - acc: 0.9825\n",
      "Epoch 20/25\n",
      "972/972 [==============================] - 0s 123us/step - loss: 0.0462 - acc: 0.9928\n",
      "Epoch 21/25\n",
      "972/972 [==============================] - 0s 107us/step - loss: 0.0455 - acc: 0.9907\n",
      "Epoch 22/25\n",
      "972/972 [==============================] - 0s 105us/step - loss: 0.0393 - acc: 0.9907\n",
      "Epoch 23/25\n",
      "972/972 [==============================] - 0s 116us/step - loss: 0.0361 - acc: 0.9959\n",
      "Epoch 24/25\n",
      "972/972 [==============================] - 0s 136us/step - loss: 0.0388 - acc: 0.9907\n",
      "Epoch 25/25\n",
      "972/972 [==============================] - 0s 255us/step - loss: 0.0313 - acc: 0.9949\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = data_generator(df)\n",
    "# Create DL model \n",
    "model = Sequential()\n",
    "model.add(Dense(units=35, activation='relu', input_dim=x_train.shape[1]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(x_train, y_train, epochs=25, batch_size=16, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 75us/step\n",
      "Deep Learning Model:\n",
      "Training accuracy is: 0.995\n",
      "Test accuracy is: 1.0\n",
      "Test f-score is: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_score = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"Deep Learning Model:\")\n",
    "print(\"Training accuracy is: {:.3f}\".format(hist.history['acc'][24]))\n",
    "print(\"Test accuracy is: {}\".format(test_score[1]))\n",
    "print(\"Test f-score is: {}\".format(test_score[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
